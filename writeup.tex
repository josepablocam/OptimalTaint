\documentclass[]{article}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{proof}
\usepackage{amssymb}
\usepackage{listings}

\newcommand{\ignore}[1]{}
\newcommand{\lsyn}{[\![}
\newcommand{\rsyn}{]\!]}

\newtheorem{defn}{Definition}

\newtheorem{thm}{Theorem}

\newtheorem{lem}{Lemma}
\newtheorem{ex}{Example}

\newcommand{\todo}[1]{textnormal{{\color{black} [[ #1 ]]}}}
%\newcommand{\todo}[1]{#1}

% A command to highlight changes made by Jose as per email with Dr. Tripp
\newcommand{\jose}[1]{{\textbf{\color{blue} #1}}}


%opening
\title{Tight Taint Tracking}
\author{}

\begin{document}

\maketitle

\section{Language Syntax}

We assume, for simplicity, that programs are deterministic. The input state, which we shall often denote by $\sigma_0$, fixes the initial values of variables. The program's state is a store mapping (integral) variables to values.

\subsection{Core Syntax}

\begin{tabular}{rclc}
{\sf c} & ::= & {\sf x := aexp}\ $|$ & {\bf (aasgn)}\\
%		 & 		  & {\sf z := bexp}\ $|$ & {\bf (basgn)} \\
		 & 	 & {\sf if (bexp) \{ c \} else \{ c \}}\ $|$ & {\bf (condition)}\\
		 & 	 & {\sf while (bexp) \{ c \}}\ $|$ & {\bf (loop)}\\
		 		 & 	 & {\sf skip}\ $|$ & {\bf (nop)}\\
		 & 	 & {\sf c\ ;\ c} & {\bf (composition)}\\
{\sf aexp} & ::= & $n$\ $|$\ {\sf y}\ $|$\
%{\sf read()}\ $|$\ 
{\sf y aop z} & {\bf (aexp)} \\
{\sf aop} & ::= & $+\ |\ -\ |\ \times\ |\ /\ |\ \%$ & {\bf (aop)} \\
{\sf bexp} & ::= & {\sf true}\ $|$\ {\sf false} $|$\ {\sf x bop y}\ $|$ & \\ % {\bf (bconst)} \\
& 		 & {\sf bexp} $\wedge$ {\sf bexp}\ $|$\ {\sf bexp} $\vee$ {\sf bexp}\ $|$\ $\neg${\sf bexp} & {\bf (bexp)} \\ % {\bf (propositional)} \\
{\sf bop} & ::= & $<\ |\ >\ |\ \leq\ |\ \geq\ |\ \neq\ |\ =$ & {\bf (bop)}
\end{tabular}

\subsection{Syntax with Instrumentation Commands}

\newcommand{\shadow}[1]{\textnormal{${\sf \overline{#1}}$}}

\begin{tabular}{rclc}
	{\sf c'} & ::= & {\sf x := aexp}\ $|$ & {\bf (aasgn)}\\
%	& 		  & {\sf z := bexp}\ $|$ & {\bf (basgn)} \\
	& 	 & {\sf if (bexp) \{ c' \} else \{ c' \}}\ $|$ & {\bf (condition)}\\
	& 	 & {\sf while (bexp) \{ c' \}}\ $|$ & {\bf (loop)}\\
			 		 & 	 & {\sf skip}\ $|$ & {\bf (nop)}\\
	& 	 & {\sf c'\ ;\ c'} & {\bf (composition)}\\
			 		  &  	  & ${\sf \overline{x} := iexp}$ & {\bf (shadow)}\\
   {\sf iexp}  & ::=  & {\sf true}\ $|$\ {\sf false}\ $|$\ {\sf x bop y}\ $|$ \\
   				& 			& \shadow{y}\ $|$\ $\neg$\shadow{y}\ $|$\
\shadow{y} $\vee$ \shadow{z}\ $|$\  
   				\shadow{y} $\wedge$ \shadow{z} & {\bf (iexp)} \\
\end{tabular}

\newcommand{\instrEras}{\textnormal{$\ensuremath{eras}$}}
\newcommand{\nocommand}{\ensuremath{\textsf{skip}}}
\newcommand{\cprime}{{\sf c'}}
\newcommand{\cdprime}{{\sf c''}}
\newcommand{\bexp}{{\sf bexp}}
\paragraph{Instrumentation Erasure} We define function \instrEras\ that takes an instrumented command and returns a non-instrumented command or $\nocommand$. Intuitively, the result of \instrEras({\sf c'}) is the result of removing all of the instrumentation commands, or $\nocommand$ if \cprime\ consists only of instrumentation commands.
\[
  \instrEras(\cprime) = \begin{cases}
  {\sf if (\bexp)\ \{\ \instrEras(\cdprime)\ \}\ else\ \{\ \instrEras(\cdprime)\ \}}
  & \mbox{if } \cprime={\sf if (\bexp)\ \{ \cdprime \}\ else\ \{ \cdprime \}} \\
  \instrEras(\cdprime)\ ;\ \instrEras(\cdprime)
  & \mbox{if } \cprime={\sf \cdprime\ ;\ \cdprime} \\
{\sf while\ (\bexp)\ \{\ \instrEras(\cdprime)\ \}}
& \mbox{if } \cprime={\sf while\ (\bexp)\ \{ \cdprime \}} \\
	\nocommand
  & \mbox{if } \cprime = {\sf \textnormal{\shadow{z}} := iexp} \\
	\cprime
    & \mbox{otherwise} \\
  \end{cases}
\]

Note that shadow variables are boolean, and that shadow expressions cannot be assigned to regular variables. That is, shadow values cannot escape the shadow state. Stated differently, if program {\sf c} is identical to program {\sf c'} modulo shadow statements, then
$$
	\forall \sigma \in \Sigma.\ \lsyn {\sf c} \rsyn \sigma \equiv \lsyn {\sf \instrEras(c')} \rsyn \sigma
$$
That is, {\sf c} and {\sf c'} are semantically equivalent up to the values assigned to shadow variables.

%& 		 & {\sf x := $n$}\ $|$ & {\bf (aconst)}\\
%& 		 & {\sf x := {\sf b}}\ $|$ & {\bf (abool)}\\
%& 		 & {\sf x := read()}\ $|$ & {\bf (input)}\\
%& 		 & {\sf x := y aop z}\ $|$ & {\bf (aexp)}\\
%& 	 & {\sf if (b) \{ c \} else \{ c \}}\ $|$ & {\bf (condition)}\\
%& 	 & {\sf while (b) \{ c \}}\ $|$ & {\bf (loop)}\\
%& 	 & {\sf c\ ;\ c} & {\bf (composition)}\\
%
%{\sf b} & ::= & {\sf true}\ $|$\ {\sf false} $|$ & {\bf (bconst)} \\
%& 		 & {\sf b} $\wedge$ {\sf b}\ $|$\ {\sf b} $\vee$ {\sf b}\ $|$\ $\neg${\sf b}\ $|$ & {\bf (propositional)} \\
%&        & {\sf x bop $n$}	& {\bf (bexp)}\\
%$\overline{{\sf b}}$ & ::= & {\sf true}\ $|$\ {\sf false} $|$ & {\bf (bconst)} \\
%& 		 & {\sf b} $\wedge$ {\sf b}\ $|$\ {\sf b} $\vee$ {\sf b}\ $|$\ $\neg${\sf b}\ $|$ & {\bf (propositional)} \\
%&        & {\sf x bop $n$}	& {\bf (bexp)}\\
%
%$\overline{\sf b}$ & ::= & ${\sf b}\ |\ $ & 


\section{Program Trace}

We define the trace function, $t$, as follows:
\[ 
t({\sf c},\sigma) = \begin{cases} 
t({\sf c}_1,\sigma) &
	\mbox{if } {\sf c}={\sf if (b)\ \{ c_1 \}\ else\ \{ c_2 \}},\lsyn {\sf b} \rsyn\sigma = {\sf true} \\ 
t({\sf c}_2,\sigma) &
	\mbox{if } {\sf c}={\sf if (b)\ \{ c_1 \}\ else\ \{ c_2 \}},\lsyn {\sf b} \rsyn\sigma = {\sf false} \\ 
\epsilon &
	\mbox{if } {\sf c}={\sf while (b)\ \{ c_1 \}},\lsyn {\sf b} \rsyn\sigma = {\sf false} \\ 
t({\sf c}_1\ ;\ {\sf c},\sigma) &
	\mbox{if } {\sf c}={\sf while (b)\ \{ c_1 \}},\lsyn {\sf b} \rsyn\sigma = {\sf true} \\ 
t({\sf c}_1,\sigma) \cdot t({\sf c}_2,\lsyn {\sf c}_1 \rsyn \sigma) &
	\mbox{if } {\sf c}={\sf c}_1\ ;\ {\sf c}_2 \\ 
{\sf c} & 
	\mbox{otherwise}
\end{cases}
\]

We define the branching function, $\rho$, as follows (where $\pi_i$ projects a tuple onto its $i$th element):
\[ 
\rho({\sf c},\sigma,n) = \begin{cases} 
({\sf b}_n,n+1) &
	\mbox{if } {\sf c}={\sf if (b)\ \{ c_1 \}\ else\ \{ c_2 \}},\lsyn {\sf b} \rsyn\sigma = {\sf true} \\ 
(\neg {\sf b}_n,n+1) &
	\mbox{if } {\sf c}={\sf if (b)\ \{ c_1 \}\ else\ \{ c_2 \}},\lsyn {\sf b} \rsyn\sigma = {\sf false} \\ 
(\neg {\sf b}_n,n+1) &
	\mbox{if } {\sf c}={\sf while (b)\ \{ c_1 \}},\lsyn {\sf b} \rsyn\sigma = {\sf false} \\ 
({\sf b}_n \wedge \pi_1(\rho({\sf c}_1\ ;\ {\sf c},\sigma,n+1)),k) &\mbox{if } {\sf c}={\sf while (b)\ \{ c_1 \}},\lsyn {\sf b} \rsyn\sigma = {\sf true} \\ 
& \textit{where}\ k = \pi_2(\rho({\sf c}_1\ ;\ {\sf c},\sigma,n+1)) \\
(\pi_1(\rho({\sf c}_1,\sigma,n)) \wedge  \pi_1(\rho({\sf c}_2,\lsyn {\sf c}_1 \rsyn \sigma,k_1)),k_2) &\mbox{if } {\sf c}={\sf c}_1\ ;\ {\sf c}_2 \\ 
& \textit{where} \\
& \quad k_1 = \pi_2(\rho({\sf c}_1,\sigma,n)) \\
& \quad k_2 = \pi_2(\rho({\sf c}_2,\lsyn {\sf c}_1 \rsyn \sigma,k_1)) \\
{\sf true} & \mbox{otherwise}
\end{cases}
\]
Note that $\rho$ is fully deterministic. Though branching decisions are potentially dependent on input values, these are encoded into the state $\sigma$ (i.e., the second argument).

\newcommand{\prog}{{\sf c}}
\newcommand{\progp}{{\sf c'}}
\newcommand{\xvar}{\textsf{x}}
\newcommand{\yvar}{\textsf{y}}
\newcommand{\zvar}{\textsf{z}}
\newcommand{\query}[2]{\textnormal{$#1 \leadsto #2$}}
\section{The Tainting Property}

\subsection{The \query{\xvar}{\yvar} Judgment}

Given program \prog\ and initial state $\sigma_0$, we are interested in queries of the form \query{\xvar}{\yvar}. Assuming the execution of \prog\ starting from $\sigma_0$ terminates, \query{\xvar}{\yvar} denotes \jose{that the value of \xvar\ in $\sigma_0$ influences the value of \yvar\ }through a sequence of assignments. Formally, the judgment \query{\xvar}{\yvar} consists of the following rules:
\[
\infer{\epsilon \models \query{\xvar}{\xvar}}{}
\]
\[
\infer{t \models \query{\xvar}{\yvar}}{t' \models \query{\xvar}{\zvar},t'' \models \query{\zvar}{\yvar},t=t' \cdot t''}
\]
\[
\infer{[{\sf z := e}] \cdot t \models \query{\xvar}{\yvar}}{t \models \query{\zvar}{\yvar},\xvar \in {\sf vars}({\sf e})}
\]
\[
\infer{[{\sf z := e}] \cdot t \models \query{\xvar}{\yvar}}{t \models \query{\xvar}{\yvar},\xvar \neq \zvar}
\]
\[
\infer{[\nocommand] \cdot t \models \query{\xvar}{\yvar}}{t \models \query{\xvar}{\yvar}}
\]

A sound solution is to maintain the set of all tainted variables at every point along the trace. This amounts to maintaining a shadow variable $\overline{{\sf x}}$ per each program variable ${\sf x}$ and instrumenting every variable definition with another instruction for the purpose of taint tracking. 

\jose{Note that this approach can be extended to handle multiple queries of the form \query{\xvar}{\yvar} by creating shadow variables indexed by the appropriate query.}

\subsection{Sound, Complete, Precise and Optimal Tracking Schemes}

A taint instrumentation scheme $s$ accepts as input a program \prog\ without instrumentation (i.e., based on the core grammar) as well as a query \query{\xvar}{\yvar}, and outputs an instrumented version \progp\ of \prog\ (i.e., according to the extended grammar). $s$ has the full discretion to insert whatever instrumentation statements it deems needed. Our sole assumption is that $s$ introduces, and maintains, a privileged shadow variable
\shadow{qxy}, such that in every terminating execution of \progp, with final state $\sigma'$, $\lsyn$\shadow{qxy}$\rsyn \sigma'$ denotes the determination by $s$ whether or not \query{\xvar}{\yvar}.

\begin{defn}[Sound tracking scheme] We refer to $s$ as being a \emph{sound} tracking scheme if
	$$
		\lsyn \shadow{qxy} \rsyn \sigma' \Longrightarrow \query{\xvar}{\yvar}
	$$
\end{defn}

\begin{defn}[Complete tracking scheme] We refer to $s$ as being a \emph{complete} tracking scheme if
	$$
	\query{\xvar}{\yvar} \Longrightarrow \lsyn \shadow{qxy} \rsyn \sigma'
	$$
\end{defn}

\begin{defn}[Precise tracking scheme] We refer to $s$ as being a \emph{precise} tracking scheme if $s$ is both sound and complete:
	$$
	\query{\xvar}{\yvar} \Longleftrightarrow \lsyn \shadow{qxy} \rsyn \sigma'
	$$
\end{defn}

\newcommand{\cnt}{\ensuremath{cnt}}

\begin{defn}[Optimal tracking scheme] Let \cnt\ be a function that, given an instrumented version \progp\ of \prog\ and an initial state $\sigma_0$, 
	counts the number of instrumentation commands in $t(\progp,\sigma_0)$ (all of the form {\sf \shadow{x} := exp}). Let $s$ be a precise tracking scheme. $s$ is considered \emph{optimal} if for any other precise tracking scheme $s'$,
	it holds that
	$$
		\forall \prog.\ \forall \sigma \in \Sigma.\ 
		\cnt(t(\prog'_s,\sigma)) \leq \cnt(t(\prog'_{s'},\sigma))
	$$
	where $\prog'_s$ and $\prog'_{s'}$ are the instrumented versions of \prog\ due to $s$ and $s'$, respectively.
	That is, the number of instrumentation commands introduced by $s$ is minimal.
\end{defn}

\newcommand{\cupdot}{\mathbin{\mathaccent\cdot\cup}}

\newcommand{\Tp}{\textnormal{$T^p$}}
\newcommand{\Tn}{\textnormal{$T^n$}}

\section{Reasoning about Optimality via Control Flow}

Given program \prog\ with set $T$ of finite traces (and potentially other infinite traces), we partition $T$ in two:
$$
\begin{array}{rccc}
T = & \{ t \colon t \models \query{\xvar}{\yvar} \} & \cupdot & \{ t \colon t \not\models \query{\xvar}{\yvar} \} \\
     &  \underbrace{~~~~~~~~~~~~~~~~~}_{\Tp}  &    & \underbrace{~~~~~~~~~~~~~~~~~}_{\Tn} \\
\end{array}
$$
where we denote the LHS set by \Tp\ and the RHS set by \Tn.

For each trace $t \in T$, there exists $\sigma_0 \in \Sigma$ such that
\begin{itemize}
	\item $t=t(\prog,\sigma_0)$
	\item $[ \ldots, {\sf b}^t_i, \ldots ] = \rho(\prog,\sigma_0,1)$ (where ${\sf b}^t_i$ is a branching literal)
\end{itemize}
That is, $\rho$ collects the branching decisions along $t$. (Note that $\sigma_0$ is not necessarily unique.)

Given the above, we can describe the exact branching conditions that give rise to taint flow between \xvar\ and \yvar\ as follows:
\begin{equation}\label{Eq:preciseCond}
	\phi^P = \bigvee_{t \in \Tp} \bigwedge_i {\sf b}^t_i 
\end{equation}
That is, each trace is a conjunction of branching literals. $\phi^P$ is the disjunction of all these conjunctions, essentially enumerating all traces that carry taint from \xvar\ to \yvar.
Analogously, we define
\begin{equation}\label{Eq:preciseNegCond}
	\phi^N = \bigvee_{t \in \Tn} \bigwedge_i {\sf b}^t_i 
\end{equation}

Our goal is to find the essential branching decisions that characterize \emph{precisely} when \query{\xvar}{\yvar}. We state this problem formally in terms of $\phi^P$ and $\phi^N$ above.

\newcommand{\asgn}{\textnormal{$\mathbb{A}$}}
\newcommand{\asgnL}{\textnormal{$\mathbb{A}_L$}}
\newcommand{\asgnLP}{\textnormal{$\mathbb{A}_{L'}$}}

Recall the definition of an \emph{interpolant} (aka \emph{Craig interpolant}) \cite{XXX}. Given a pair $(A,B)$ of propositional formulas, \jose{such that $A$ and $B$ are inconsistent}, propositional formula $P$ is an interpolant for this pair iff
\begin{enumerate}
	\item $A \implies P$;
	\item $P \wedge B$ is unsatisfiable; and
	\item $P$ refers only to the common variables of $A$ and $B$.
\end{enumerate}

As we are about to argue, we are interested in a formula $\psi$, such that
\begin{enumerate}
	\item $\phi^P \implies \psi$;
	\item $\psi \wedge \phi^N$ is unsatisfiable; and
	\item $\psi$ refers only to the common variables of $\phi^P$ and $\phi^N$; and
	\item $\psi$ is minimal (i.e., there is no formula $\psi'$ satisfying the conditions above, such that $\psi \implies \psi'$).
\end{enumerate}
That is, we are interested in a \emph{minimal} interpolant for the pair $(\phi^P,\phi^N)$.
The argument, stated simply, is that we seek to converge on the weakest differentiation between benign and tainted traces (that is, w.r.t. \query{\xvar}{\yvar}); hence the applicability of Craig interpolation.

\ignore{
\begin{defn}[The optimality order] Let $\psi$ be a formula ranging over set $L$ of atoms, and $\psi'$ another formula. We define partial order $\prec$, such that $\psi' \prec \psi$ if the following three conditions hold:
	\item $\psi'$ ranges over set $L' \subseteq L$ of atoms.
	\item Any assignment \asgnLP\ to the literals $L'$ such that $\lsyn \psi' \rsyn_{\asgnLP}$ can be completed into an assignment \asgnL\ to the literals $L$ such that $\lsyn \psi \rsyn_{\asgnL}$.
	\item For any assignment \asgnLP\ to the literals $L'$ such that $\neg \lsyn \psi' \rsyn_{\asgnLP}$, there is no assignment \asgnL\ to the literals $L$ that is a completion of \asgnLP\ such that $\lsyn \psi \rsyn_{\asgnL}$.
\end{defn}
}

\begin{thm}[Guarantees thanks to minimal interpolant]\label{Th:optimal} 
	The following statements hold true of a formula $\psi$ that is a minimal interpolant for $(\phi^P,\phi^N)$:
	\begin{enumerate}
		\item $\psi$ captures the precise set of instrumentation points to evaluate \query{\xvar}{\yvar}. (Hence we refer to $\psi$ as the \emph{optimal instrumentation formula}.)
		\item In general, computing $\prog$ is an undecidable problem. (Note that $\phi^P$ and $\phi^N$ are not necessarily finite.)
		\item For a program \prog\ with finitely many traces, computing $\psi$ is decidable yet NP-hard.
		\item $\psi$ is not unique in general.
	\end{enumerate}
	\begin{proof}
		Write me! (O: not sure about claims)
	\end{proof}
\end{thm}

\newcommand{\bi}[1]{\textnormal{${\sf b}_{#1}$}}

\begin{ex}[Single instrumentation point] The example in Figure \ref{Fi:example} illustrates the benefit of the optimal scheme. We end up instrumenting only one branching point: \bi{0}. Indeed, the optimal formula, as specified in Theorem \ref{Th:optimal} above, is simply $\psi = \bi{0}$. The original formula $\phi$ is significantly more complex, having to account for all the downstream branching points, which are irrelevant to the query at hand. Naive taint tracking is also arbitrarily worse, since we have to attach shadow variables (and commands) to all the variables $x_i$.
\end{ex}

\begin{figure}
\begin{lstlisting}[language=Java,escapeinside={<>}]
// original variables: <\xvar>,<\xvar$_1$>,<\xvar$_2$>,...,<\xvar$_n$>,<\yvar>
// shadow variables: <\shadow{x}>, <\shadow{qxy}>
if (<\xvar> > 0) { // <\bi{0}>
  /* INSTRUMENTATION - BGN */
  <\shadow{x}> := true;
  /* INSTRUMENTATION - END */
  <\xvar$_1$> := x+1; // flow from <\xvar> to <\xvar$_1$>
  <\xvar$_2$> := x<$_1$>+2; // flow from <\xvar$_1$> to <\xvar$_2$>
  ...
  <\xvar$_n$> := <\xvar$_{n-1}$> + <$n$>; // flow from <\xvar$_{n-1}$> to <\xvar$_n$> 
  if (<\xvar$_1$> > 1) { <\xvar$_1$> = <\xvar$_1$>-1; } // <\bi{1}>
  if (<\xvar$_2$> > 2) { <\xvar$_2$> = <\xvar$_2$>-2; } // <\bi{2}>
  ...
  if (<\xvar$_n$> > n) { <\xvar$_n$> = <\xvar$_n$>-<$n$>; } // <\bi{n}>       
} else {
  /* INSTRUMENTATION - BGN */
  <\shadow{x}> := false;
  /* INSTRUMENTATION - END */
  <\xvar$_n$> = 0; }
<\yvar> = <\xvar$_n$>;
/* INSTRUMENTATION - BGN */
<\shadow{qxy}> := <\shadow{x}>;
/* INSTRUMENTATION - END */
\end{lstlisting}
\caption{\label{Fi:example}Program that conditionally carries taint from \xvar\ to \yvar}
\end{figure}

\ignore{
\begin{thm}[Decidability for loop-free programs] Assume that program \prog\ is loop free (as in Example \ref{Fi:example}). Then the problem of finding an optimal instrumentation formula $\psi$ is decidable, and the resulting instrumentation scheme is guaranteed to be optimal.
	\begin{proof}
		Write me!
	\end{proof}
\end{thm}
}




\ignore{
\section{Taint Tracking}

Given program {\sf c} sans instrumentation with traces $T[{\sf c}]$ that defines variable {\sf x}, let $T^{\sf x}[{\sf c}] \subseteq T[{\sf c}]$ be the subset of traces $t$ of {\sf c} such that $t \models \odot \rightarrow {\sf x}$.

\begin{defn}[Instrumentation for taint tracking] We refer to an instrumentation scheme $s$ as a \emph{taint tracking scheme} w.r.t. variable {\sf x} if 
the scheme defines a privileged shadow variable $\overline{\sf x}_t$, such that 
along any execution of the instrumented version {\sf c'} of {\sf c}, $\overline{\sf x}_t$ is defined and is live in the final state. $\overline{\sf x}_t$ denotes the judgment made by the scheme whether or not {\sf x} is tainted.
\end{defn}

\begin{defn}[Sound tracking scheme] We refer to the taint tracking scheme as \emph{sound} if for any trace $t$ of ${\sf c'}$, 
	$\lsyn {\sf \overline{x}_t} \rsyn \sigma' \implies t \models \odot \rightarrow {\sf x}$ , where $\sigma'$ denotes the final state in execution $t$.
\end{defn}

\begin{defn}[Complete tracking scheme] We refer to the taint tracking scheme as \emph{complete} if for any trace $t$ of ${\sf c'}$, 
	$t \models \odot \rightarrow {\sf x} \implies \lsyn {\sf \overline{x}_t} \rsyn \sigma'$, where $\sigma'$ denotes the final state in execution $t$.
\end{defn}

\begin{defn}[Precise tracking scheme] We refer to the taint tracking scheme as \emph{precise} if it is both sound and complete.
\end{defn}

\begin{lem}[Preciseness of naive tracking] The standard tracking scheme of allocating a shadow variable per each program variable is sound and complete. 
\end{lem}

\begin{defn}[Optimal taint condition] Given trace $t \in T^{\sf x}[{\sf c}]$,
	corresponding to input state $\sigma$, $\pi_1(\rho({\sf c}, \sigma, 1))$ is
	a conjunctive propositional formula $\bigwedge_i {\sf b}^t_i$. Define:
	$$
		\phi = \bigvee_{t \in T^{\sf x}[{\sf c}]} \bigwedge_i {\sf b}^t_i 
	$$
	We refer to $\psi$ as the \emph{optimal taint condition} if
	$$
	(\psi \implies \phi) \wedge (\forall \psi'.\ (\psi' \implies \phi) \implies (\psi \implies \psi'))
	$$
	That is, $\psi$ is the weakest logical condition that implies $\phi$.
\end{defn}

\begin{defn}[Optimal tracking scheme] A tracking scheme $s$ is \emph{sufficient} w.r.t. the optimal taint condition, $\psi$, if for any input state $\sigma$, the shadow final state $\overline{\sigma'}$ suffices to evaluate $\psi$. $s$ is \emph{optimal} if there is no other scheme $s'$, such that
	$$
	\forall \sigma \in \Sigma.\ \overline{\sigma'}_{s'} \sqsubseteq  \overline{\sigma'}_{s} \wedge \exists \sigma \in \Sigma.\ \overline{\sigma'}_{s'} \sqsubset  \overline{\sigma'}_{s}
	$$
	
\end{defn}

\subsection{Possible Cost Functions}

Two possible cost functions are (i) the number (or proportion) of shadow variables and (ii) the number (or proportion) of instrumentation instructions.

\subsection{Optimizations w.r.t. Default Taint Tracking} 

Given program ${\sf p}$, we denote by $T({\sf p})$ the set of all traces of execution of ${\sf p}$. We define an equivalence relation $\equiv$ over queries $q$ of the form $\{ \odot \rightarrow {\sf x} \}$ (abbreviated as $\odot \rightarrow {\sf x}$) as follows:
\begin{quote}
$q \equiv q'
\Longleftrightarrow \forall \pi \in T({\sf p}).\ t \models q \Leftrightarrow t \models q'$
\end{quote}
That is, assuming $q$ is $\odot \rightarrow {\sf x}$ and $q'$
is $\odot \rightarrow {\sf y}$, there is no execution of ${\sf p}$ such that ${\sf x}$ is tainted but not ${\sf y}$ or vice versa.
 
\paragraph{Redundancy Elimination.} Assuming the ability to detect equivalent queries, effectively reducing to ``correlated'' variables, an immediate optimization is to track taint w.r.t. a representative of each equivalence class rather than the entire class.

\paragraph{Relaxation: Probabilistic Inference.} In the absence of the ability to prove that two variables are correlated, we may instead cast the problem into a probabilistic setting, which we can instantiate via testing. Assume for example that across $n$ (random and independent) executions of the program, a pair of variables has a high degree of correlation. We can utilize Bayesian reasoning or another form of statistical prediction to perform inference across variables/queries.

\section{Problem Definition}
Need to define the language with shadow variables. That is,
  define the syntax and semantics of the language. Syntax should allow
assignments to shadow variables $\overline{x} := e$ where $e$ can
contain both shadow variables and regular program variables. Let's
assume/require that shadow variables are boolean valued. Note that
normal assignment (i.e., to non-shadow variables) and tests of if and
while statements cannot use shadow variables.

Define what it means for ${\sf c}'$ to be an instrumented version of {\sf c} (i.e.,
when you erase the assignments to shadow variables from ${\sf c}'$,
you have exactly ${\sf c}$. Some simple results such as if we have an
execution of ${\sf c}$ then we have an equivalent execution of ${\sf
  c}'$ and vice versa. That is, showing it really is just
instrumentation and not changing anything fundamental about the computation.

Given a program {\sf c} and a variable {\sf x}, we are interested in
knowing whether the execution of {\sf c} results in {\sf x} being
tainted at the end of execution. I suggest for simplicity that
  we restrict our attention to just terminating program executions.

That is, we are interested in the sets $tainted = \{ t \mid t =
t({\sf c},\sigma) \land t \models \{ \odot \rightarrow {\sf x} \} \}$ and
$untainted = \{ t \mid
t = t({\sf c},\sigma) \land t \not\models \{ \odot \rightarrow {\sf x} \} \}$
I think we may want different notation for this, or something a bit more
concise?
Note that $tainted$ and $untainted$ do not partition the set of
traces, since some traces could be infinite. It may be even better to initially not think about loops...

We can say that instrumentation correctly determines taint for {\sf x}
if we have ${\sf c}'$, which an instrumented version of {\sf c} such
that when one partitions the final shadow states of the executions of
${\sf c}'$, that partition refines $tainted$ and
$untainted$. Something like:
If ${\sf c}', \sigma_1 \Downarrow \sigma'_1$ and ${\sf c}', \sigma_2
\Downarrow \sigma'_2$ and $\sigma'_1 =_\mathit{shadow} \sigma'_2$ then
either $t({\sf c},\sigma_1)$ and $t({\sf c},\sigma_2)$ are both in $tainted$ or 
$t({\sf c},\sigma_1)$ and $t({\sf c},\sigma_2)$ are both in $untainted$. That is, the shadow
state suffices to tell whether $\sf x$ is tainted.

Now we can define \emph{optimal taint instrumentation}, meaning that
we have a correct instrumentation that is optimal in some cost
function, e.g., size of shadow state, static number of assignments to
shadow state, dynamic number of assignments to shadow state,
... actually do this formally.

I(Steve) have some thoughts about heuristics for finding optimal
instrumentation in the loop-free case, but probably not worth writing
down here at the moment. First step is to cleanly and crisply define
the problem.

In general, finding the optimal taint instrumentation will be
undecidable \todo{this needs a proof, or at least a proof sketch}. But
it gives us a definition of how well we could possibly do in any
actual implementation. \todo{Could we use information theory to
  approximate the number of bits that are needed? That is, if there is
$n$ information theoretic bits required to distinguish tainted from
untainted executions (assuming uniform distribution of input states), then it is likely(???) we will need at least $n$ physical bits, i.e., $n$
shadow variables.}


\section{Probabilistic}

We can extend the definitions above if we assume that we have a
probability distribution on input states, or alternatively if we add a
probabilistic choice operator. The key thing is to get a probability
distribution (or subdistribution if we have non-terminating programs)
on traces.

Then we can relax``correctness of instrumentation'' to ``probability of correctness of
instrumentation'' by considering the probability that instrumentation
is correct. 

\section{Practical tool}

\section{Optimal solution}

Let $\rho$ be the function that derives, given execution trace $t$, the branching points incident in $t$ and the truth value of the associated boolean conditions. We thus obtain for trace $t$ a sequence of the form: $[ \ldots , {\sf c}/{\sf b}, \ldots ]$, which --- assuming as we do that the program is fully deterministic --- can be reduced to $[ \ldots, {\sf b}, \ldots]$ without loss of information.

\section{Random Thoughts}

\begin{itemize}
	\item Taint tracking depends only on the path (not the values).
	\item Can we prove that we can reduce standard taint tracking to tracking of path conditions? (There is no additional complexity cost.)
	\item We start from the loop-free case. We can prove soundness and completeness.
	\item When adding in loops, we can add boolean variables but with abstraction.
	\item Can we use a temportal logic that characterizes precisely/imprecisely the taint-related branching events, then we can come up with an effective scheme.
\end{itemize}
}

\end{document}
